<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Huangkai,huankai"><title>Hadoop简介与安装 | HuangkaiのBlog</title><link rel="stylesheet" type="text/css" href="//fonts.neworld.org/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.1"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.1"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Hadoop简介与安装</h1><a id="logo" href="/.">HuangkaiのBlog</a><p class="description">学而不思则罔 思而不学则殆</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="Arama"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">Hadoop简介与安装</h1><div class="post-meta"><a href="/2018/07/09/01_Hadoop介绍与集群配置/#comments" class="comment-count"></a><p><span class="date">Jul 09, 2018</span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><h1 id="一、Hadoop介绍"><a href="#一、Hadoop介绍" class="headerlink" title="一、Hadoop介绍"></a>一、Hadoop介绍</h1><p>Hadoop 是Apache 旗下用java语言实现的开源软件框架，是一个开发和运行处理大规模数据的软件平台，允许使用简单的编程模型在大量的计算机集群上对大型数据进行分布式处理。</p>
<p>Hadoop目前有1.x / 2.x / 3.x 三个大版本：</p>
<ul>
<li>1.x : 主要由 HDFS(分布式文件系统（redundant reliable storage）) 和 MapReduce(分布式运算变成框架(cluster resource management &amp; data processing)) 组件构成。</li>
<li>2.x : 主要有 HDFS 、YARN(作业调度和集群资源管理框架) 、 MapReduce Or  Others 组件构成。在1.x版本中，MapReduce主要是集群资源管理，在2.x版本中YARN做集群资源管理和作业调度，MapReduce只用于数据处理，也可以使用其它的一些技术做数据管理。</li>
<li>3.x : 刚出来的新版本。</li>
</ul>
<p>Hadoop是 Apache Lucene 创始人Dou Cutting 创建的，最早起源于Nutch,它是Lucene(全文检索框架)的子项目，Nutch的设计目标是构建一个大型的全网搜索引擎，包括网页抓取、索引、查询等功能。但随着抓取网页数量的增加，遇到了严重的可扩展性问题，如何解决数十亿网页的存储问题和索引问题。<br>2003年Google发表了一篇论文为该问题提供了可行的解决方案，论文中描述的是谷歌的产品架构，该架构称为：<strong><a href="https://pan.baidu.com/s/1oWdpypk2d8WnH2Z8R_s3jQ" target="_blank" rel="noopener">谷歌分布式文件系统(GFS)</a></strong>,可以解决在网页爬取和索引过程中产生的超大文件的存储需求。<br>2004年,Google发表论文向全世界介绍了谷歌版的<strong><a href="https://pan.baidu.com/s/1YrRUlpoSXg0OQ8NYP0X2rg" target="_blank" rel="noopener">MapReduce</a></strong>系统。<br>同时期，Nutch的开发人员完成了相应的开源实现HDFS和 MapReduce，并从Nutch中剥离出来成为独立的Hadoop项目，到2008年1月，Hadoop成为Apache顶级项目，迎来了它的快速发展期。<br>2006年Google发表了论文是关于<strong><a href="https://pan.baidu.com/s/1NsK-L0lOmFUedgh2DiJlfg" target="_blank" rel="noopener">BigTable</a></strong>的，这促使了后来的Hbase的发展。<br>因此，Hadoop极其生态圈的发展离不开Google的贡献。</p>
<h1 id="二、Hadoop的特性"><a href="#二、Hadoop的特性" class="headerlink" title="二、Hadoop的特性"></a>二、Hadoop的特性</h1><ul>
<li>扩容能力：Hadoop是在可用的计算机集群之间分配数据并完成计算任务的，这些集群可以方便的扩展到数以千计的节点中； </li>
<li>成本低：Hadoop通过普通廉价的机器组成服务器集群来分发以及处理数据，以至于成本很低； </li>
<li>高效率：通过并发数据，Hadoop可以在节点之间动态并行的移动数据，使得速度非常快；</li>
<li>可靠性：能自动维护数据的多份复制，并且在任务失败后能自动重新部署(redeploy) 计算任务，所以Hadoop的按位存储和处理数据的能力值得信赖。</li>
</ul>
<h1 id="三、集群安装"><a href="#三、集群安装" class="headerlink" title="三、集群安装"></a>三、集群安装</h1><p>集群介绍：<br>Hadoop集群具体来说包括两个集群：HDFS集群和YARN集群，两者逻辑上分离(HDFS的运行不影响YARN,YARN的运行也不影响HDFS)，但物理上常部署在一起(HDFS和YARN可以部署在同一服务器上)。</p>
<ul>
<li>HDFS 集群负责海量数据的存储，集群中的角色主要有：NameNode、DataNode、SecondaryNameNode(相当于NameNode的秘书)</li>
<li>YARN集群负责海量数据运算时的资源调度，集群中的角色主要有：ResourceManager、NodeManager</li>
<li>Mapreduce 其实是一个分布式运算编程的框架，是应用程序开发包，由用户按照编程规范进行程序开发，打包运行在HDFS集群上并且受到YARN集群的资源调度管理。</li>
</ul>
<p>Hadoop 常用的集群方式有三种:</p>
<ul>
<li>Standlone mode(独立模式),只在单机部署，仅一台机器运行一个java进程 ，主要用于调试；</li>
<li>Pseude-Distributed mode(伪分布模式)，只在单机部署，一台机器运行HDFS的NameNode、DataNode、YARN的ResourceManager、NodeManager,但分别启用单独的java进程 ，主要用于调试；</li>
<li>Cluster mode(集群模式):生产环境部署，会使用N 台主机组成一个Hadoop集群，主节点与从节点会分开部署在不同服务器上。</li>
</ul>
<h2 id="3-1、安装前配置"><a href="#3-1、安装前配置" class="headerlink" title="3.1、安装前配置"></a>3.1、安装前配置</h2><p>操作系统: <strong>CentOS Linux release 7.3.1611 (Core) </strong><br>JDK版本: <strong> 1.8.0_144 </strong><br>Hadoop版本: <strong>hadoop-2.9.1</strong><br>关闭防火墙: <strong>systemctl stop firewalld</strong><br>设置防火墙开机禁止启动: <strong>systemctl disable firewalld</strong><br>配置主机名(三台机器都需要配置)： <strong>vim /etc/hosts</strong><br><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">192.168</span>.<span class="number">64.128</span>  hadoop-<span class="keyword">node</span><span class="title">-1</span></span><br><span class="line"><span class="number">192.168</span>.<span class="number">64.129</span>  hadoop-<span class="keyword">node</span><span class="title">-2</span></span><br><span class="line"><span class="number">192.168</span>.<span class="number">64.130</span>  hadoop-<span class="keyword">node</span><span class="title">-3</span></span><br></pre></td></tr></table></figure></p>
<p>重启网卡: <strong>systemctl restart network</strong><br>使用 ping 命令检查是否配置成功(三台机器都需要配置成功)，这一步必须不能出错<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[root@sjq-02 ~]#<span class="built_in"> ping </span>-c 3 hadoop-node-1</span><br><span class="line">PING hadoop-node-1 (192.168.64.128) 56(84) bytes of data.</span><br><span class="line">64 bytes <span class="keyword">from</span> brokerserver1 (192.168.64.128): <span class="attribute">icmp_seq</span>=1 <span class="attribute">ttl</span>=64 <span class="attribute">time</span>=0.523 ms</span><br><span class="line">64 bytes <span class="keyword">from</span> brokerserver1 (192.168.64.128): <span class="attribute">icmp_seq</span>=2 <span class="attribute">ttl</span>=64 <span class="attribute">time</span>=1.71 ms</span><br><span class="line">64 bytes <span class="keyword">from</span> brokerserver1 (192.168.64.128): <span class="attribute">icmp_seq</span>=3 <span class="attribute">ttl</span>=64 <span class="attribute">time</span>=1.69 ms</span><br><span class="line"></span><br><span class="line">--- hadoop-node-1<span class="built_in"> ping </span>statistics ---</span><br><span class="line">3 packets transmitted, 3 received, 0% packet loss, time 2001ms</span><br><span class="line">rtt min/avg/max/mdev = 0.523/1.309/1.713/0.555 ms</span><br><span class="line">[root@sjq-02 ~]# </span><br><span class="line">[root@sjq-02 ~]#<span class="built_in"> ping </span>-c 3 hadoop-node-2</span><br><span class="line">PING hadoop-node-2 (192.168.64.129) 56(84) bytes of data.</span><br><span class="line">64 bytes <span class="keyword">from</span> brokerserver2 (192.168.64.129): <span class="attribute">icmp_seq</span>=1 <span class="attribute">ttl</span>=64 <span class="attribute">time</span>=0.013 ms</span><br><span class="line">64 bytes <span class="keyword">from</span> brokerserver2 (192.168.64.129): <span class="attribute">icmp_seq</span>=2 <span class="attribute">ttl</span>=64 <span class="attribute">time</span>=0.024 ms</span><br><span class="line">64 bytes <span class="keyword">from</span> brokerserver2 (192.168.64.129): <span class="attribute">icmp_seq</span>=3 <span class="attribute">ttl</span>=64 <span class="attribute">time</span>=0.024 ms</span><br><span class="line"></span><br><span class="line">--- hadoop-node-2<span class="built_in"> ping </span>statistics ---</span><br><span class="line">3 packets transmitted, 3 received, 0% packet loss, time 1999ms</span><br><span class="line">rtt min/avg/max/mdev = 0.013/0.020/0.024/0.006 ms</span><br><span class="line">[root@sjq-02 ~]# </span><br><span class="line">[root@sjq-02 ~]#<span class="built_in"> ping </span>-c 3 hadoop-node-3</span><br><span class="line">PING hadoop-node-3 (192.168.64.130) 56(84) bytes of data.</span><br><span class="line">64 bytes <span class="keyword">from</span> hadoop-node-3 (192.168.64.130): <span class="attribute">icmp_seq</span>=1 <span class="attribute">ttl</span>=64 <span class="attribute">time</span>=0.846 ms</span><br><span class="line">64 bytes <span class="keyword">from</span> hadoop-node-3 (192.168.64.130): <span class="attribute">icmp_seq</span>=2 <span class="attribute">ttl</span>=64 <span class="attribute">time</span>=1.36 ms</span><br><span class="line">64 bytes <span class="keyword">from</span> hadoop-node-3 (192.168.64.130): <span class="attribute">icmp_seq</span>=3 <span class="attribute">ttl</span>=64 <span class="attribute">time</span>=0.975 ms</span><br><span class="line"></span><br><span class="line">--- hadoop-node-3<span class="built_in"> ping </span>statistics ---</span><br><span class="line">3 packets transmitted, 3 received, 0% packet loss, time 2004ms</span><br><span class="line">rtt min/avg/max/mdev = 0.846/1.060/1.360/0.219 ms</span><br><span class="line">[root@sjq-02 ~]#</span><br></pre></td></tr></table></figure></p>
<p>配置免密登陆(128可以使用 <strong>ssh</strong> 免密登陆128、129和130三台服务器<font color="red">注意:128也需要配置</font>):<br>在128服务器上执行如下：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">第一步：生成公钥私钥</span></span><br><span class="line">[root@sjq-01 ~]# ssh-keygen -t rsa</span><br><span class="line"><span class="meta">#</span><span class="bash">输入以上命令，按下三个回车。</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">第二步：按锁头</span></span><br><span class="line"><span class="meta">#</span><span class="bash">命令语法为: ssh-copy-id -i ~/.ssh/id_rsa.pub &lt;romte_ip&gt;</span></span><br><span class="line"><span class="meta">#</span><span class="bash">如果你的ssh端口不是默认的22,可以使用 -p 参数指定端口号,如:（ssh-copy-id -i ~/.ssh/id_rsa.pub -p 24 &lt;romte_ip&gt;）</span></span><br><span class="line"><span class="meta">#</span><span class="bash">分别执行 128、129、130</span></span><br><span class="line">[root@sjq-01 ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub 192.168.64.128</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">回车输入密码即可使用 (ssh 192.168.64.128) 登陆到128服务器，</span></span><br><span class="line"><span class="meta">#</span><span class="bash">配置免密登陆129和130服务器也是如此。</span></span><br></pre></td></tr></table></figure></p>
<p>部署环境:</p>
<table>
<thead>
<tr>
<th style="text-align:center">主机</th>
<th style="text-align:center">IP</th>
<th style="text-align:center">角色分配</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">hadoop-node-1</td>
<td style="text-align:center">192.168.64.128</td>
<td style="text-align:center">NameNode、DataNode、ResourceManager</td>
</tr>
<tr>
<td style="text-align:center">hadoop-node-2</td>
<td style="text-align:center">192.168.64.129</td>
<td style="text-align:center">DataNode、NodeManager、SecondaryNameNode</td>
</tr>
<tr>
<td style="text-align:center">hadoop-node-3</td>
<td style="text-align:center">192.168.64.130</td>
<td style="text-align:center">DataNode、NodeManager</td>
</tr>
</tbody>
</table>
<h2 id="3-2、安装JDK-1-8"><a href="#3-2、安装JDK-1-8" class="headerlink" title="3.2、安装JDK 1.8"></a>3.2、安装JDK 1.8</h2><p>安装方式网上一大把，这里略过。</p>
<h2 id="3-3、安装Hadoop"><a href="#3-3、安装Hadoop" class="headerlink" title="3.3、安装Hadoop"></a>3.3、安装Hadoop</h2><p>下载 Hadoop : <a href="">http://hadoop.apache.org/releases.html#Download</a></p>
<p>解压到指定的目录: <strong>tar -zxvf hadoop-2.9.1.tar.gz -C /usr/local/</strong> </p>
<p>配置环境变量: <strong>vim /etc/profile</strong> ,在末尾添加如下内容:<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">HADOOP_HOME</span>=/usr/local/hadoop-2.9.1</span><br><span class="line"><span class="comment">#注意，hadoop的bin 和sbin都配置成环境变量，sbin就是super bin的简写，其实也是调用了bin目录中的相关脚本。</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$HADOOP_HOME</span>/bin:$HADOOP_HOME/sbin:$PATH</span><br></pre></td></tr></table></figure></p>
<p>重新使配置文件生效: <strong>source /etc/profile</strong></p>
<h1 id="四、Hadoop配置文件修改-每台机器执行"><a href="#四、Hadoop配置文件修改-每台机器执行" class="headerlink" title="四、Hadoop配置文件修改(每台机器执行)"></a>四、Hadoop配置文件修改(每台机器执行)</h1><h2 id="3-1、-hadoop-env-sh"><a href="#3-1、-hadoop-env-sh" class="headerlink" title="3.1、 hadoop-env.sh"></a>3.1、 hadoop-env.sh</h2><p>该文件设置的是Hadoop运行时需要的环境变量，JAVA_HOME是必须设置的，即使当前系统环境变量中配置了JAVA_HOME,它也是不能识别的，因为Hadoop即使在本机上运行，它也会把当前的执行环境当成远程服务器。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim $&#123;HADOOP_HOME&#125;/etc/hadoop/hadoop-env.sh</span></span><br><span class="line"><span class="builtin-name">export</span> JAVA_HOME= JAVA_HOME的绝对路径</span><br></pre></td></tr></table></figure>
<h2 id="3-2、core-site-xml"><a href="#3-2、core-site-xml" class="headerlink" title="3.2、core-site.xml"></a>3.2、core-site.xml</h2><p>hadoop的核心配置文件，有默认的配置项目 core-default.xml</p>
<figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="xml"><span class="comment">&lt;!-- 指定 Hadoop 所使用的文件系统schema（URI），HDFS的老大(NameNode)的地址,协议可以是 hdfs://  tfs:// file:// gfs:// 等 --&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop-node-1:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="comment">&lt;!-- 指定 Hadoop 运行时产生文件的存储目录，默认为 /tmp/hadoop-$</span></span><span class="template-variable">&#123;user.name&#125;</span><span class="xml"><span class="comment"> --&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/data/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br></pre></td></tr></table></figure>
<h2 id="3-3、hdfs-site-xml"><a href="#3-3、hdfs-site-xml" class="headerlink" title="3.3、hdfs-site.xml"></a>3.3、hdfs-site.xml</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定 HDFS副本备份数量，默认为3 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定 Hadoop secondaryNameNode 节点地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-node-2:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="3-4、mapred-site-xml"><a href="#3-4、mapred-site-xml" class="headerlink" title="3.4、mapred-site.xml"></a>3.4、mapred-site.xml</h2><p>进入 ${HADOOP_HOME}/etc/hadoop目录下，你会发现并没有 mapred-site.xml文件，而是有一个mapred-site.xml.template文件，这是 mapred-site.xml 的模板文件，使用 mv 命令重命名:<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-attr">[root@sjq-01 hadoop]</span># <span class="selector-tag">mv</span> <span class="selector-tag">mapred-site</span><span class="selector-class">.xml</span><span class="selector-class">.template</span> <span class="selector-tag">mapred-site</span><span class="selector-class">.xml</span></span><br></pre></td></tr></table></figure></p>
<p>修改配置内容：<strong>vim mapred-site.xml</strong><br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定 mapreduce 运行时的框架，这里指定  yarn ，默认是 local --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.frameworkname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="3-5、yarn-site-xml"><a href="#3-5、yarn-site-xml" class="headerlink" title="3.5、yarn-site.xml"></a>3.5、yarn-site.xml</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定YARN 的老大 (ResourceManager)地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-node-1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- NodeManager上运行的附属服务，需配置成 mapreduce_shuffle 才可以运行Mapreduce程序，默认值为 mapreduce.shuffle --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="3-6、slaves"><a href="#3-6、slaves" class="headerlink" title="3.6、slaves"></a>3.6、slaves</h2><p>此文件写上从节点的主机名，每一行写一个主机名<br><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop-<span class="keyword">node</span><span class="title">-1</span></span><br><span class="line">hadoop-<span class="keyword">node</span><span class="title">-2</span></span><br><span class="line">hadoop-<span class="keyword">node</span><span class="title">-3</span></span><br></pre></td></tr></table></figure></p>
<h2 id="3-7、关于Hadoop-的配置文件"><a href="#3-7、关于Hadoop-的配置文件" class="headerlink" title="3.7、关于Hadoop 的配置文件"></a>3.7、关于Hadoop 的配置文件</h2><p>以上我们主要修改的都 <code>***-site.xml</code>配置文件，在Hadoop中，有这些默认的只读的配置文件， core-default.xml, hdfs-default.xml, yarn-default.xml and mapred-default.xm 配置文件，这里面配置了hadoop的默认配置选项，如果用户没有修改，这些文件中的配置将会生效；</p>
<p><code>***-site.xml</code> 这些配置了用户自定义的配置选项<br>site 配置选项的优先级会大于 default 文件中的配置，如果有配置的话，就会覆盖 <code>***-default.xml</code> 中的配置选项。</p>
<p>所有的配置文件选项，可以在官网文档中查询:<br>core-default.xml ：<br>  <a href="http://hadoop.apache.org/docs/r2.9.1/hadoop-project-dist/hadoop-common/core-default.xml" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.9.1/hadoop-project-dist/hadoop-common/core-default.xml</a><br>hdfs-default.xml ：<br>  <a href="http://hadoop.apache.org/docs/r2.9.1/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.9.1/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml</a><br>mapred-default.xml ：<br>  <a href="http://hadoop.apache.org/docs/r2.9.1/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.9.1/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml</a><br>yarn-default.xml ：<br>  <a href="http://hadoop.apache.org/docs/r2.9.1/hadoop-yarn/hadoop-yarn-common/yarn-default.xml" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.9.1/hadoop-yarn/hadoop-yarn-common/yarn-default.xml</a><br>与上个版本相比过时的配置 ：<br>  <a href="http://hadoop.apache.org/docs/r2.9.1/hadoop-project-dist/hadoop-common/DeprecatedProperties.html" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.9.1/hadoop-project-dist/hadoop-common/DeprecatedProperties.html</a></p>
<h2 id="3-8-、每台服务器复制配置"><a href="#3-8-、每台服务器复制配置" class="headerlink" title="3.8 、每台服务器复制配置"></a>3.8 、每台服务器复制配置</h2><p>以上6个配置文件修改完成后，将 128上的 ${HADOOP_HOME}目录上传到 129 和 130两台服务器上:<br><figure class="highlight moonscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@sjq<span class="number">-02</span> <span class="keyword">local</span>]# scp -r /usr/<span class="keyword">local</span>/hadoop<span class="number">-2.9</span><span class="number">.1</span> root@<span class="number">192.168</span><span class="number">.64</span><span class="number">.129</span>:/usr/<span class="keyword">local</span></span><br><span class="line">[root@sjq<span class="number">-02</span> <span class="keyword">local</span>]# scp -r /usr/<span class="keyword">local</span>/hadoop<span class="number">-2.9</span><span class="number">.1</span> root@<span class="number">192.168</span><span class="number">.64</span><span class="number">.130</span>:/usr/<span class="keyword">local</span></span><br></pre></td></tr></table></figure></p>
<p>修改 129 和 130 两台服务器上的环境变量(分别在129 和 130上执行以下命令):<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@sjq-02 ~]# vim /etc/profile</span><br><span class="line"><span class="comment"># 添加如下内容</span></span><br><span class="line"><span class="attribute">HADOOP_HOME</span>=/usr/local/hadoop-2.9.1</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$HADOOP_HOME</span>/bin:$HADOOP_HOME/sbin:$PATH</span><br><span class="line"></span><br><span class="line">[root@sjq-02 ~]# source /etc/profile</span><br></pre></td></tr></table></figure></p>
<h1 id="五、Hadoop-集群启动"><a href="#五、Hadoop-集群启动" class="headerlink" title="五、Hadoop 集群启动"></a>五、Hadoop 集群启动</h1><h2 id="5-1、启动方式"><a href="#5-1、启动方式" class="headerlink" title="5.1、启动方式"></a>5.1、启动方式</h2><p>要启动Hadoop集群，需要启动HDFS 和 YARN两个集群。<br>注意：<font color="red"><strong>首次启动HDFS时，必须对其进行格式化操作。</strong></font>本质上是一些清理和准备工作，因为此时的HDFS在物理上还是不存在的。后续不再需要格式化。格式化的操作在HDFS集群的主角色（namenode） 所在服务器上操作即可。</p>
<figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@sjq<span class="number">-01</span> ~]# hdfs namenode -<span class="keyword">format</span> # 或者hadoop namenode -<span class="keyword">format</span></span><br></pre></td></tr></table></figure>
<p>单节点依次启动：</p>
<ul>
<li>在主节点上使用以下命令启动HDFS NameNode:</li>
</ul>
<figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root<span class="symbol">@sjq</span><span class="number">-01</span> ~]<span class="meta"># hadoop-daemon.sh start namenode</span></span><br></pre></td></tr></table></figure>
<ul>
<li>在每个从节点上使用以下命令启动HDFS DataNode:</li>
</ul>
<figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root<span class="symbol">@sjq</span><span class="number">-01</span> ~]<span class="meta"># hadoop-daemon.sh start datanode</span></span><br></pre></td></tr></table></figure>
<ul>
<li>在主节点上使用以下命令启动YARN ResourceManager:</li>
</ul>
<figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root<span class="symbol">@sjq</span><span class="number">-01</span> ~]<span class="meta"># yarn-daemon.sh start resourcemanager</span></span><br></pre></td></tr></table></figure>
<ul>
<li>在每个从节点上使用以下命令启动YARN nodemanager:</li>
</ul>
<figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root<span class="symbol">@sjq</span><span class="number">-01</span> ~]<span class="meta"># yarn-daemon.sh start nodemanager</span></span><br></pre></td></tr></table></figure>
<p>以上脚本位于 ${HADOOP_HOME}/sbin 目录 下，如果想要停止某个角色，只需要把命令中的 <code>start</code> 改为 <code>stop</code> 即可。</p>
</div><div class="tags"><a href="/tags/Hadoop/">Hadoop</a></div><div class="post-share"><div class="bdsharebuttonbox"><span style="float:left;line-height: 28px;height: 28px;font-size:16px;font-weight:blod">分享到：</span><a href="#" data-cmd="more" class="bds_more"></a><a href="#" data-cmd="mshare" title="分享到一键分享" class="bds_mshare"></a><a href="#" data-cmd="fbook" title="分享到Facebook" class="bds_fbook"></a><a href="#" data-cmd="twi" title="分享到Twitter" class="bds_twi"></a><a href="#" data-cmd="linkedin" title="分享到linkedin" class="bds_linkedin"></a><a href="#" data-cmd="youdao" title="分享到有道云笔记" class="bds_youdao"></a><a href="#" data-cmd="evernotecn" title="分享到印象笔记" class="bds_evernotecn"></a><a href="#" data-cmd="weixin" title="分享到微信" class="bds_weixin"></a><a href="#" data-cmd="qzone" title="分享到QQ空间" class="bds_qzone"></a><a href="#" data-cmd="tsina" title="分享到新浪微博" class="bds_tsina"></a></div></div><div class="post-nav"><a href="/2018/07/09/02_Hadoop_NameNode/" class="pre">Hadoop - NameNode 介绍</a><a href="/2018/07/09/Git_04_GitLab/" class="next">GitLab 搭建及配置</a></div><div id="comments"></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#一、Hadoop介绍"><span class="toc-text">一、Hadoop介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#二、Hadoop的特性"><span class="toc-text">二、Hadoop的特性</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#三、集群安装"><span class="toc-text">三、集群安装</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1、安装前配置"><span class="toc-text">3.1、安装前配置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2、安装JDK-1-8"><span class="toc-text">3.2、安装JDK 1.8</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3、安装Hadoop"><span class="toc-text">3.3、安装Hadoop</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#四、Hadoop配置文件修改-每台机器执行"><span class="toc-text">四、Hadoop配置文件修改(每台机器执行)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1、-hadoop-env-sh"><span class="toc-text">3.1、 hadoop-env.sh</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2、core-site-xml"><span class="toc-text">3.2、core-site.xml</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3、hdfs-site-xml"><span class="toc-text">3.3、hdfs-site.xml</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-4、mapred-site-xml"><span class="toc-text">3.4、mapred-site.xml</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-5、yarn-site-xml"><span class="toc-text">3.5、yarn-site.xml</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-6、slaves"><span class="toc-text">3.6、slaves</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-7、关于Hadoop-的配置文件"><span class="toc-text">3.7、关于Hadoop 的配置文件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-8-、每台服务器复制配置"><span class="toc-text">3.8 、每台服务器复制配置</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#五、Hadoop-集群启动"><span class="toc-text">五、Hadoop 集群启动</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1、启动方式"><span class="toc-text">5.1、启动方式</span></a></li></ol></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/07/09/vue_01/">Vue 简介</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/09/Browsersync/">browsersync(浏览器同步工具)</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/09/Redis_06_主从复制(哨兵机制)/">Redis 主从复制</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/09/10_其它改进/">其它改进</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/09/09_http改进/">全新的HTTP API</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/09/08_Stream改进/">API改进_Stream API</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/09/07_集合改进/">API改进_集合</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/09/06_标识符&String/">语法改进_标识符&String</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/09/05_异常处理/">语法改进_try</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/09/04_钻石操作符/">语法改进_钻石操作符(泛型 [Diamond operator])</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/Redis/" style="font-size: 15px;">Redis</a> <a href="/tags/ETL/" style="font-size: 15px;">ETL</a> <a href="/tags/Git/" style="font-size: 15px;">Git</a> <a href="/tags/JPA/" style="font-size: 15px;">JPA</a> <a href="/tags/Docker/" style="font-size: 15px;">Docker</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Mac/" style="font-size: 15px;">Mac</a> <a href="/tags/MySql/" style="font-size: 15px;">MySql</a> <a href="/tags/Nginx/" style="font-size: 15px;">Nginx</a> <a href="/tags/Idea/" style="font-size: 15px;">Idea</a> <a href="/tags/Tool/" style="font-size: 15px;">Tool</a> <a href="/tags/Spring-Cloud/" style="font-size: 15px;">Spring Cloud</a> <a href="/tags/Spring-Boot/" style="font-size: 15px;">Spring-Boot</a> <a href="/tags/Svn/" style="font-size: 15px;">Svn</a> <a href="/tags/Thymeleaf/" style="font-size: 15px;">Thymeleaf</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/JDK9/" style="font-size: 15px;">JDK9</a> <a href="/tags/Vue/" style="font-size: 15px;">Vue</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">七月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">二月 2018</a></li></ul></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">Baidu Site Haritası</a> |  <a href="/atom.xml">订阅</a> |  <a href="/about/">关于</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次</p><p><span> Copyright &copy;<a href="/." rel="nofollow">Huangkai.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.1"></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.1" async></script><script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":["mshare","weixin","tsina","qzone","linkedin","fbook","twi","print","renren","sqq","evernotecn","bdysc","tqq","tqf","bdxc","kaixin001","tieba","douban","bdhome","thx","ibaidu","meilishuo","mogujie","diandian","huaban","duitang","hx","fx","youdao","sdo","qingbiji","people","xinhua","mail","isohu","yaolan","wealink","ty","iguba","h163","copy"],"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"]}};with(document)0[(getElementsByTagName('head')[0]||head).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script></body></html>